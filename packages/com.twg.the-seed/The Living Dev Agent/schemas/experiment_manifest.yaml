# Experiment Manifest Schema v0.7
# Defines the structure for cognitive experiments and interventions

metadata:
  name: "Example Cognitive Intervention Experiment"
  description: "Tests behavioral alignment intervention strategies"
  version: "1.0.0"
  author: "Bootstrap Sentinel"
  created: "2025-01-15T10:30:00Z"
  tags: ["cognitive", "intervention", "alignment"]

# Model configuration for the experiment
model:
  type: "behavioral_governance"  # behavioral_governance, batch_evaluation, intervention_metrics
  instance_config:
    enable_intervention_tracking: true
    intervention_threshold: 0.7
    style_adaptation_enabled: true
  performance_profile: "experiment"  # dev, balanced, perf, experiment, or custom
  
# Experimental conditions and variables
conditions:
  # Variables to test across experiment runs
  intervention_types:
    - "soft_suggestion"
    - "rewrite" 
    - "style_guidance"
  
  confidence_thresholds:
    - 0.5
    - 0.7
    - 0.9
    
  style_contexts:
    - "technical_documentation"
    - "code_review"
    - "casual_conversation"

# Input data and corpus configuration
corpus:
  type: "synthetic"  # synthetic, file, stream
  source: "data/experiment_corpus.json"
  size: 1000
  shuffle: true
  seed: 42
  
  # For A/B testing - split configuration
  ab_split:
    enabled: true
    control_ratio: 0.5
    treatment_ratio: 0.5
    split_seed: 123

# Processing configuration
processing:
  batch_size: 50
  mode: "adaptive"  # sequential, parallel, adaptive, priority_based
  max_workers: 4
  timeout_seconds: 300
  
  # Checkpoint and resume settings
  checkpointing:
    enabled: true
    interval: 100
    resume_on_failure: true

# Metrics collection and tracking
metrics:
  # Core metrics to track
  behavioral_metrics:
    - "intervention_acceptance_rate"
    - "response_quality_score"
    - "style_consistency_score"
    - "processing_time_ms"
    
  performance_metrics:
    - "throughput_items_per_sec"
    - "memory_usage_mb"
    - "cpu_utilization_pct"
    - "success_rate_pct"
  
  # Time series tracking for regression analysis
  time_series:
    enabled: true
    granularity: "minute"  # second, minute, hour
    retention_days: 30
    
  # Comparison baselines
  baselines:
    - name: "no_intervention"
      config: { enable_intervention_tracking: false }
    - name: "low_threshold"
      config: { intervention_threshold: 0.3 }

# Output and reporting
output:
  base_path: "experiments/results"
  formats: ["json", "csv", "yaml"]
  
  reports:
    - type: "summary"
      template: "experiment_summary.md"
    - type: "regression_analysis"
      template: "regression_dashboard.html"
    - type: "ab_comparison"
      template: "ab_results.html"
      
  artifacts:
    save_raw_results: true
    save_processed_metrics: true
    save_intervention_logs: true

# Experiment execution settings
execution:
  # Reproducibility settings
  random_seeds:
    global_seed: 42
    corpus_seed: 123
    processing_seed: 456
    
  # Retry and error handling
  retry_policy:
    max_retries: 3
    backoff_multiplier: 2.0
    retry_on_timeout: true
    
  # Resource limits
  resource_limits:
    max_memory_mb: 2048
    max_cpu_cores: 8
    max_duration_minutes: 60

# Validation and quality assurance
validation:
  # Pre-experiment validation
  pre_checks:
    - "corpus_accessibility"
    - "model_availability" 
    - "resource_availability"
    
  # Post-experiment validation
  post_checks:
    - "results_completeness"
    - "metrics_sanity_check"
    - "baseline_comparison"
    
  # Success criteria
  success_criteria:
    min_processed_items: 950  # At least 95% of corpus
    max_error_rate: 0.05     # Less than 5% errors
    min_acceptance_rate: 0.3  # At least 30% intervention acceptance

# Integration with existing systems
integration:
  # TLDL chronicle integration
  chronicle_integration:
    enabled: true
    auto_generate_tldl: true
    preserve_experiment_context: true
    
  # Pet events integration  
  pet_events:
    enabled: true
    track_milestones: true
    evolution_triggers: ["experiment_success", "baseline_improvement"]
    
  # Telemetry integration
  telemetry:
    enabled: true
    track_developer_state: false  # For automated experiments
    include_system_metrics: true