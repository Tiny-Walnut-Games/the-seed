name: Test Suite - Release Validation

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

jobs:
  # =====================================================================
  # UNIT TESTS (Fast, no infrastructure)
  # =====================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-asyncio pytest-timeout
          pip install -r requirements-gpu.txt 2>/dev/null || echo "GPU requirements optional"

      - name: Run unit tests (@pytest.mark.unit)
        run: |
          python -m pytest tests/ -m "unit" -v --tb=short
          python -m pytest "packages/com.twg.the-seed/The Living Dev Agent/tests/" -m "unit" -v --tb=short 2>/dev/null || echo "WARBLER tests optional"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-results
          path: .test_results/

  # =====================================================================
  # INTEGRATION TESTS (Medium, cross-module)
  # =====================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-asyncio pytest-timeout
          pip install -r requirements-gpu.txt 2>/dev/null || echo "GPU requirements optional"

      - name: Run integration tests (@pytest.mark.integration)
        run: |
          python -m pytest tests/ -m "integration" -v --tb=short
          python -m pytest "packages/com.twg.the-seed/The Living Dev Agent/tests/" -m "integration" -v --tb=short 2>/dev/null || echo "WARBLER tests optional"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: .test_results/

  # =====================================================================
  # E2E TESTS (Slow, real system connections)
  # =====================================================================
  e2e-tests:
    name: E2E Tests (Real Systems)
    runs-on: ubuntu-latest
    timeout-minutes: 60

    services:
      stat7-server:
        image: stat7-local:latest
        options: >-
          --health-cmd="curl -f http://localhost:8000 || exit 1"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
        ports:
          - 8000:8000
          - 8765:8765

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-asyncio pytest-timeout playwright
          pip install -r requirements-gpu.txt 2>/dev/null || echo "GPU requirements optional"

      - name: Install Playwright browsers
        run: |
          playwright install chromium

      - name: Wait for STAT7 server
        run: |
          python -c "
          import socket
          import time
          timeout = 30
          start = time.time()
          while time.time() - start < timeout:
              try:
                  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                  s.connect(('localhost', 8000))
                  s.close()
                  print('‚úì STAT7 server is ready')
                  exit(0)
              except:
                  time.sleep(1)
          print('‚úó STAT7 server failed to start')
          exit(1)
          "

      - name: Run E2E tests (@pytest.mark.e2e)
        run: |
          python -m pytest tests/ -m "e2e" -v --tb=short
          python -m pytest "packages/com.twg.the-seed/The Living Dev Agent/tests/" -m "e2e" -v --tb=short 2>/dev/null || echo "WARBLER tests optional"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-results
          path: .test_results/

  # =====================================================================
  # TEST AUDIT (Verify markers and mocks)
  # =====================================================================
  test-audit:
    name: Test Quality Audit
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Run test marker assignment (dry-run)
        run: |
          python assign_test_markers.py 2>&1 | tail -30

      - name: Audit E2E tests for mocks
        run: |
          python audit_e2e_mocks.py

      - name: Verify test markers
        run: |
          python -m pytest tests/ --collect-only -q | head -50

  # =====================================================================
  # SUMMARY & REPORTING
  # =====================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, test-audit]
    if: always()

    steps:
      - name: Download all test results
        uses: actions/download-artifact@v3

      - name: Print test summary
        run: |
          echo "=========================================="
          echo "‚úÖ TEST SUITE SUMMARY"
          echo "=========================================="
          echo ""
          echo "Unit Tests:        ${{ needs.unit-tests.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "E2E Tests:         ${{ needs.e2e-tests.result }}"
          echo "Test Audit:        ${{ needs.test-audit.result }}"
          echo ""
          echo "=========================================="

      - name: Fail if any test failed
        if: |
          needs.unit-tests.result == 'failure' ||
          needs.integration-tests.result == 'failure' ||
          needs.e2e-tests.result == 'failure' ||
          needs.test-audit.result == 'failure'
        run: |
          echo "‚ùå Some tests failed. See results above."
          exit 1

      - name: Success message
        if: success()
        run: |
          echo "‚úÖ All tests passed! Release candidate is ready."
          echo ""
          echo "Test Coverage:"
          echo "  - üî≤ Unit Tests (mocks allowed)"
          echo "  - üîó Integration Tests (mixed real/mock)"
          echo "  - üöÄ E2E Tests (real systems only, no mocks)"
          echo ""
          echo "Next steps:"
          echo "  1. Review test results in artifacts"
          echo "  2. Check data integrity in E2E test logs"
          echo "  3. Verify admin entity viewer connects"
          echo "  4. Create release notes with known limitations"